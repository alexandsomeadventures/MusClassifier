{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11869732,"sourceType":"datasetVersion","datasetId":7459197}],"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code]\n# %% [code]\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torchaudio.transforms as T\nimport torch.optim as optim\nimport torch.nn as nn\nimport numpy as np\nimport torchaudio\nimport torch\nimport json\nimport os\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nPATH = './musclassifier.pth'\nmelspec = T.MelSpectrogram(n_mels = 32)\nval_patience = 4\nbatch_size = 1024\nnum_epochs = 50\nlast_epoch = 0 \nfeatures = 24\nclasses = ['bass','brass','flute','guitar','keyboard','mallet','organ','reed','string','synth_lead','vocal']\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n\n\nclass NSynthDataset(Dataset):\n    def __init__(self, inputs_dir, labels_dir, transform = None):\n        self.inputs_dir = inputs_dir\n        self.labels_dir = labels_dir\n        self.transform = transform\n\n        with open(self.labels_dir, 'r') as f:\n            self.labels = json.load(f)\n\n        self.labels_list = list(self.labels.items())\n       \n    def __len__(self):\n        return len(self.labels_list)\n\n    def __getitem__(self, idx):\n        try:\n            filename, data = self.labels_list[idx]\n            \n            path = os.path.join(self.inputs_dir,filename +'.wav')\n            \n            waveform, sample_rate = torchaudio.load(path)\n            waveform = F.pad(waveform, (0, max(0, 64000 - waveform.shape[-1])))[:, :64000]\n            new_spec = melspec(waveform.mean(dim=0))\n            new_spec = torch.log(new_spec + 1e-10)\n            new_spec = new_spec.unsqueeze(0)\n    \n            instrument = data[\"instrument_family\"]\n            return new_spec, instrument\n        except Exception as e:\n            print(f'Error at {idx}:\\n', e)\n\n        \n\ndataloaders = {\n    'train': DataLoader(NSynthDataset('/kaggle/input/nsynth-train/nsynth-train.jsonwav/nsynth-train/audio', \n                                      '/kaggle/input/nsynth-train/nsynth-train.jsonwav/nsynth-train/examples.json'), \n                        batch_size=batch_size,shuffle=True,num_workers=4,prefetch_factor=2,pin_memory=True,persistent_workers=True),\n\n    'valid': DataLoader(NSynthDataset('/kaggle/input/nsynth-train/nsynth-valid.jsonwav/nsynth-valid/audio', \n                                      '/kaggle/input/nsynth-train/nsynth-valid.jsonwav/nsynth-valid/examples.json'), \n                        batch_size=batch_size,shuffle=True,num_workers=4,prefetch_factor=2,pin_memory=True,persistent_workers=True),\n\n    'test': DataLoader(NSynthDataset('/kaggle/input/nsynth-train/nsynth-test.jsonwav/nsynth-test/audio', \n                                     '/kaggle/input/nsynth-train/nsynth-test.jsonwav/nsynth-test/examples.json'), \n                       batch_size=batch_size,shuffle=True,num_workers=4,prefetch_factor=2,pin_memory=True,persistent_workers=True)\n}\n# for GPU = ,num_workers=4,prefetch_factor=2,pin_memory=True,persistent_workers=True\n# for TPU = without\n\nclass SelfAttention(nn.Module):\n    def __init__(self, dim, num_heads = 4, qkv_bias = False, proj_bias = True):\n        super().__init__()\n        assert dim % num_heads == 0\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        \n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.proj = nn.Linear(dim, dim, bias=proj_bias)\n    def forward(self, x, mask=None):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv.unbind(0)\n        out = F.scaled_dot_product_attention(q,k,v, mask)\n        out = out.transpose(1, 2).reshape(B, N, C)\n        out = self.proj(out)\n        return out\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, features, kernel_size = 3, stride = 1, padding=1)\n        self.bn1 = nn.BatchNorm2d(features)\n        self.dropout1 = nn.Dropout2d(0.3)\n        self.conv2 = nn.Conv2d(features, 48, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(48)\n        self.dropout2 = nn.Dropout2d(0.2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.attn1 = SelfAttention(48)\n        self.fc1 = nn.Linear(48, 96)\n        self.dropout3 = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(96, len(classes))\n        \n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = self.dropout1(x)\n        \n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = self.dropout2(x)\n        \n        B, C, H, W = x.shape\n        x = x.permute(0, 2, 3, 1).reshape(B, H*W, C)\n        \n        x = self.attn1(x)\n        \n        x = x.mean(dim=1)  # shape: (B, C)\n        \n        x = F.relu(self.fc1(x))\n        x = self.dropout3(x)\n        x = self.fc2(x)\n        \n        return x\n\nmodel = CNN()\noptimizer = optim.AdamW(model.parameters(),lr=1e-3, weight_decay=1e-2)\ncosine_annealing_lr = optim.lr_scheduler.CosineAnnealingLR(optimizer,35, eta_min=0)\nexponential_lr = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\nscheduler = optim.lr_scheduler.SequentialLR(optimizer,schedulers=[cosine_annealing_lr,exponential_lr],milestones=[5])","metadata":{"_uuid":"2ee4e03f-4d09-4fc7-8c66-cbad3f96216e","_cell_guid":"f66bffc1-768b-4de2-90a1-bdd823c81033","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}