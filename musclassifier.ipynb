{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11869732,"sourceType":"datasetVersion","datasetId":7459197},{"sourceId":240799253,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import musdataset","metadata":{"execution":{"iopub.status.busy":"2025-05-20T10:39:54.671374Z","iopub.execute_input":"2025-05-20T10:39:54.672091Z","iopub.status.idle":"2025-05-20T10:39:54.675677Z","shell.execute_reply.started":"2025-05-20T10:39:54.672056Z","shell.execute_reply":"2025-05-20T10:39:54.675022Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch.nn as nn\nimport numpy as np\nimport torchaudio\nimport torch\nfrom musdataset import model, optimizer, scheduler, criterion, last_epoch, num_epochs, PATH, dataloaders\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(device))\n\n# checkpoint = torch.load(PATH)\n# model.load_state_dict(checkpoint['model'])\n# optimizer.load_state_dict(checkpoint['optimizer']) \n# scheduler.load_state_dict(checkpoint['scheduler'])\n# last_epoch = checkpoint['last_epoch']\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\nmodel = model.to(device)\n\n\n\ndef train(model, criterion, optimizer, scheduler, last_epoch,  num_epochs):\n\n    for epoch in range(last_epoch, num_epochs):       \n        print('-' * 10)\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n            correct = 0  \n            total = 0\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device, non_blocking=True)\n                labels = labels.to(device, non_blocking=True)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, predicted = torch.max(outputs, 1)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                correct += torch.sum(predicted == labels.data).item()\n                total += labels.size(0)\n            \n            if phase == 'train':\n                scheduler.step()\n\n            print(\"Epoch: \", epoch + 1 , \" | Correct/Total: \", correct, \"/\",total )\n            print(\"Accuracy: \", (correct/total) * 100, \"%\")\n    last_epoch = num_epochs\n    print(\"Training done\")\n\n\ndef test(model):\n    model.eval()\n    with torch.no_grad():\n        correct = 0  \n        total = 0\n        for inputs, labels in dataloaders['test']:\n            correct = 0  \n            total = 0\n            inputs = inputs.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            outputs = model(inputs)\n            _ , predicted = torch.max(outputs, 1)\n        \n            correct += torch.sum(predicted == labels.data)\n            total += labels.size(0)\n        print(\"Correct/Total: \", correct, \"/\",total )\n        print(\"Accuracy: \", (correct/total) * 100, \"%\")\n    \n    print(\"Testing done\")\n    \n    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(\"Number of parameters: \", total_params)\n\ndef prod(model = None): #for real demo purposes\n    pass\n\n\ntrain(model, criterion, optimizer, scheduler, last_epoch, num_epochs)\n\ncheckpoint = {\n     'model': model.state_dict(),\n     'optimizer': optimizer.state_dict(),\n     'scheduler': scheduler.state_dict(),\n     'last_epoch': last_epoch + 1\n    }\ntorch.save(checkpoint, PATH)\n\n# test(model)\n\n# prod(model)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:39:54.676864Z","iopub.execute_input":"2025-05-20T10:39:54.677130Z","iopub.status.idle":"2025-05-20T14:40:36.173553Z","shell.execute_reply.started":"2025-05-20T10:39:54.677107Z","shell.execute_reply":"2025-05-20T14:40:36.172707Z"}},"outputs":[{"name":"stdout","text":"True\nTesla T4\n----------\nEpoch:  1  | Correct/Total:  190657 / 289205\nAccuracy:  65.92451721097491 %\nEpoch:  1  | Correct/Total:  8653 / 12678\nAccuracy:  68.25209023505285 %\n----------\nEpoch:  2  | Correct/Total:  242480 / 289205\nAccuracy:  83.84364032433741 %\nEpoch:  2  | Correct/Total:  8465 / 12678\nAccuracy:  66.76920649944786 %\n----------\nEpoch:  3  | Correct/Total:  257997 / 289205\nAccuracy:  89.20903857125569 %\nEpoch:  3  | Correct/Total:  9050 / 12678\nAccuracy:  71.38349897460166 %\n----------\nEpoch:  4  | Correct/Total:  267206 / 289205\nAccuracy:  92.39328504002351 %\nEpoch:  4  | Correct/Total:  9175 / 12678\nAccuracy:  72.3694589051901 %\n----------\nEpoch:  5  | Correct/Total:  273328 / 289205\nAccuracy:  94.51012257741048 %\nEpoch:  5  | Correct/Total:  9286 / 12678\nAccuracy:  73.24499132355261 %\n----------\nEpoch:  6  | Correct/Total:  277781 / 289205\nAccuracy:  96.04986082536608 %\nEpoch:  6  | Correct/Total:  9368 / 12678\nAccuracy:  73.8917810380186 %\n----------\nEpoch:  7  | Correct/Total:  281231 / 289205\nAccuracy:  97.2427862588821 %\nEpoch:  7  | Correct/Total:  9396 / 12678\nAccuracy:  74.11263606247041 %\n----------\nEpoch:  8  | Correct/Total:  282932 / 289205\nAccuracy:  97.83095036392871 %\nEpoch:  8  | Correct/Total:  9390 / 12678\nAccuracy:  74.06530998580217 %\nTraining done\n","output_type":"stream"}],"execution_count":2}]}